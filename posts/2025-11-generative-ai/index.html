<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Brandon Davis</title><meta name=description content="UNC alum and software engineer. I love experimenting with code, discovering new places, and reading about space exploration"><meta property="og:title" content="Brandon Davis"><meta property="og:site_name" content="subdavis.com"><meta property="og:description" content="UNC alum and software engineer. I love experimenting with code, discovering new places, and reading about space exploration"><meta property="og:image" content="https://subdavis.com/img/li.jpg"><meta property="og:url" content="https://subdavis.com/"><meta name=twitter:card content="summary"><meta name=twitter:site content="@subdavis"><meta name=twitter:creator content="@subdavis"><meta name=twitter:title content="Brandon Davis"><meta name=twitter:description content="UNC alum and software engineer. I love experimenting with code, discovering new places, and reading about space exploration"><meta name=twitter:image content="https://subdavis.com/img/li.jpg"><meta name=twitter:url content="https://subdavis.com/"><link rel=icon type=image/x-icon href=/favicon.ico>
    
  
  
    
      
        <link rel="stylesheet" href="/css/main.6c2f34c174c95ec2aa4d19d6ecdfd3d648b31aeaadf8a83828e2774d3726c1c1.css" integrity="sha256-bC80wXTJXsKqTRnW7N/T1kizGuqt&#43;Kg4KOJ3TTcmwcE=" crossorigin="anonymous">
      
    
  

  
<script defer data-website-id=bfadb547-f5e5-4a8e-9416-13340a2bfdfd src=https://umami.subdavis.com/script.js data-domains=subdavis.com></script></head><body class=bg-white><div class="max-w-screen-sm mx-auto px-4"><main class="main w-full bg-white"><div class="my-6 max-w-screen-sm"><nav aria-label=Breadcrumb class=mb-6><ol class="flex flex-wrap items-center space-x-2 text-sm text-accent-600 font-mono"><li class="flex items-center space-x-2 text-nowrap"><a href=/ class="text-accent-700 hover:text-accent-700 transition-colors">Brandon Davis
</a><span class=text-accent-600>/</span></li><li class="flex items-center space-x-2 text-nowrap"><a href=/posts/ class="text-accent-700 hover:text-accent-700 transition-colors">Posts
</a><span class=text-accent-600>/</span></li><li class="flex items-center space-x-2"><span class=text-accent-700>Thinking about Generative AI</span></li></ol></nav><article class=max-w-none><header class=mb-8><h1 class="text-4xl font-bold text-accent-700 mb-2">Thinking about Generative AI</h1><time class="text-accent-600 text-sm mb-4" datetime='November 23, 2025'>November 23, 2025</time><p class="text-xl text-accent-700 italic">A time capsule journal entry</p></header><div class="prose text-accent-700 leading-6"><blockquote><p>Long before we get to the point where a machine is a moral agent, we will have machines that are capable of suffering. - Ted Chiang</p></blockquote><p>I want to write out some thoughts to revisit later. It can be easy to get revisionist about what you believed and when, so here is a list of things I thought were true in late 2025 after ~2 years of pretty extensive experience with frontier models, especially Anthropic&rsquo;s Claude.</p><h2 id=some-takes>Some takes</h2><ul><li><p>AI is alarmingly good at all sorts of things. It is good at writing code, dealing with legal documents, talking through household repairs, and many other tasks.</p></li><li><p>We are not in a bubble comparable to previous bubbles, but the market is overheated. Many participants will suffer when their bad bets fail. A sector-wide collapse followed by another &ldquo;AI winter&rdquo; is not likely, but a recession that affects regular American families feels very possible.</p></li><li><p>Environmental concerns about AI and data centers can be <a href=https://andymasley.substack.com/p/individual-ai-use-is-not-bad-for>pretty misleading</a>. Environmental harms are important to mitigate, but environmental advocates seem overly focused on data centers compared to their relative impact or the marginal cost of reducing that impact.</p></li><li><p>As the US government actively sabotages renewable energy infrastructure projects, power demands from AI companies is both <a href=https://investors.constellationenergy.com/news-releases/news-release-details/constellation-meta-sign-20-year-deal-clean-reliable-nuclear>applying positive pressure toward renewable energy transition</a> and <a href=https://stateimpactcenter.org/insights/data-centers-straining-the-grid-and-your-wallet>keeping fossil fuel plants online longer</a> than they otherwise would be.</p></li><li><p>Using AI to produce art, especially that which supplants human artists, is bad. Artists have a unique and important role in a healthy society. It&rsquo;s clear that this is already happening, and I&rsquo;m very worried about it.</p></li><li><p>Playing around and making art for personal use or amusement is mostly benign, though.</p></li><li><p>AI boosters are pretty universally untrustworthy. Most of the experts on this technology have conflicts of interest, and their incentives are not aligned with public good. We need more independent experts outside the AI industry.</p></li><li><p>AI skeptics often confuse material debates about the merits and capabilities of AI systems with larger philosophical or moral debates about capitalism. These are both important, but conflating them can result in motivated reasoning.</p></li><li><p>AI will, in the near term, accelerate wealth inequality. Skeptics are correct about this. Longer term effects depend on what we decide to do as a society.</p></li><li><p>AI will cause (mostly psychological) harm to humans at higher rates than other digital technologies. It will make harms from social media or smartphone use seem quaint. Society will mostly tolerate these harms and ignore them, just as it ignores the 1 million annual worldwide deaths from automobiles (40,000 in the US).</p></li><li><p>Large language models are not on the cusp of becoming self-aware or developing the capacity to suffer, but <a href=https://alleninstitute.org/news/one-of-worlds-most-detailed-virtual-brain-simulations-is-changing-how-we-study-the-brain/>I am still worried that we might cause machines to experience suffering in the future.</a></p></li><li><p>We have avoided nuclear holocaust thus far by luck. Nuclear disarmament should be an urgent priority. All sides of the AI discourse should agree on this.</p></li></ul><h2 id=disclaimers>Disclaimers</h2><p>Qualifiers like &ldquo;maybe&rdquo; or &ldquo;likely&rdquo; were omitted because I am uncertain about everything, and otherwise I would have placed them everywhere. My goal was to stake out some positions, not hedge against being wrong.</p><p>I am neither a skeptic nor a booster. I think these technologies are exceedingly <em>interesting</em>. The producers of LLMs are mostly untrustworthy, but the nuance has been lost. We usually don&rsquo;t blame Facebook users when Meta does something shitty.</p><p>We exist in a dynamic period where challengers across domains could leverage AI against more lethargic incumbents. Civic and social good might result if good people would be willing to selectively wield AI in service of their desired outcomes. There&rsquo;s plenty of reason to be angry at Meta, for example, but it doesn&rsquo;t make sense to stubbornly refuse to use <a href=https://www.llama.com/>Llama</a>, <a href=https://pytorch.org/>PyTorch</a>, <a href=https://ai.meta.com/sam3/>sam3</a>, or React in pursuit of a better future.</p></div><footer class="mt-8 pt-8 border-t border-accent-200 flex justify-between items-center"><a href=/posts class="text-accent-700 hover:text-accent-700">‚Üê Back to all posts
</a><a href=/index.xml title="Subscribe to RSS feed" class="inline-flex items-center gap-2" aria-label="RSS Feed"><svg class="inline w-5 h-5" fill="currentColor" viewBox="0 0 20 20"><path d="M5 3a1 1 0 000 2c5.523.0 10 4.477 10 10a1 1 0 102 0C17 8.373 11.627 3 5 3z"/><path d="M4 9a1 1 0 011-1 7 7 0 017 7 1 1 0 11-2 0 5 5 0 00-5-5A1 1 0 014 9zM3 15a2 2 0 114 0 2 2 0 01-4 0z"/></svg>
<span>Subscribe with RSS</span></a></footer></article></div></main></div></body></html>